"""
@author: Heerozh (Zhang Jianhao)
@copyright: Copyright 2024, Heerozh. All rights reserved.
@license: Apache2.0 å¯ç”¨ä½œå•†ä¸šé¡¹ç›®ï¼Œå†éšä¾¿æ‰¾ä¸ªè§’è½æåŠç”¨åˆ°äº†æ­¤é¡¹ç›® :D
@email: heeroz@gmail.com
"""

import asyncio
import logging
import random
from pathlib import Path
from typing import TYPE_CHECKING, Any, Literal, cast, final, overload, override

from msgspec import msgpack
import numpy as np
import redis

from ..base import BackendClient, RaceCondition, RowFormat

if TYPE_CHECKING:
    import redis.asyncio
    import redis.asyncio.cluster
    import redis.cluster
    import redis.exceptions

    from ...component import BaseComponent
    from ..idmap import IdentityMap
    from ..table import TableReference
    from .maint import RedisTableMaintenance
    from .worker_keeper import RedisWorkerKeeper

logger = logging.getLogger("HeTu.root")


@final
class RedisBackendClient(BackendClient, alias="redis"):
    """å’ŒRedisåç«¯çš„æ“ä½œçš„ç±»ï¼ŒæœåŠ¡å™¨å¯åŠ¨æ—¶ç”±server.pyæ ¹æ®Configåˆå§‹åŒ–"""

    @staticmethod
    def _get_referred_components() -> list[type["BaseComponent"]]:
        """è·å–å½“å‰appç”¨åˆ°çš„Componentåˆ—è¡¨"""
        from ....system.definer import SystemClusters

        return [comp_cls for comp_cls in SystemClusters().get_components().keys()]

    def _lua_schema_definitions(self) -> str:
        """ç”Ÿæˆluaè„šæœ¬é‡Œç”¨åˆ°çš„schemaå®šä¹‰éƒ¨åˆ†"""
        # todo ä¸è¯¥åœ¨è¿™è€¦åˆsystemçš„ä¸œè¥¿ï¼Œ luaæ”¹æˆç›´æ¥stack cmd

        # è¯»å–namespaceä¸‹çš„æ‰€æœ‰schemaå®šä¹‰ï¼Œç„¶åæ›¿æ¢luaè„šæœ¬é‡Œçš„schemaå®šä¹‰
        # ["User:{CLU1}"] = {
        #     unique = { ["email"] = true, ["phone"] = true },
        #     indexes = { ["email"] = false, ["age"] = true, ["phone"] = true }
        # }
        lua_schema_def = ["{"]
        for comp_cls in self._get_referred_components():
            lua_schema_def.append(f'["{comp_cls.component_name_}"] = {{')
            # unique
            lua_schema_def.append("unique = {")
            for field in comp_cls.uniques_:
                lua_schema_def.append(f'["{field}"] = true,')
            lua_schema_def.append("},")
            # indexes
            lua_schema_def.append("indexes = {")
            for field, is_str in comp_cls.indexes_.items():
                str_flag = "true" if is_str else "false"
                lua_schema_def.append(f'["{field}"] = {str_flag},')
            lua_schema_def.append("},")
            lua_schema_def.append("},")
        lua_schema_def.append("}")
        return "\n".join(lua_schema_def)

    def load_commit_scripts(self, file: str | Path):
        assert self._async_ios, "è¿æ¥å·²å…³é—­ï¼Œå·²è°ƒç”¨è¿‡close"
        assert self.is_servant is False, (
            "Servantä¸å…è®¸åŠ è½½Luaäº‹åŠ¡è„šæœ¬ï¼ŒLuaäº‹åŠ¡è„šæœ¬åªèƒ½åœ¨Masterä¸ŠåŠ è½½"
        )
        assert len(self._async_ios) == 1, (
            "Luaäº‹åŠ¡è„šæœ¬åªèƒ½åœ¨Masterä¸ŠåŠ è½½ï¼Œä½†å½“å‰è¿æ¥æ± ä¸­æœ‰å¤šä¸ªæœåŠ¡å™¨"
        )
        # read file to text
        with open(file, "r", encoding="utf-8") as f:
            script_text = f.read()

        # replace PLACEHOLDER_SCHEMA_DEFINITIONS in script_text
        script_text = script_text.replace(
            "PLACEHOLDER_SCHEMA", self._lua_schema_definitions()
        )

        with open(str(file) + ".debug.lua", "w", encoding="utf-8") as f:
            _ = f.write(script_text)

        # ä¸Šä¼ è„šæœ¬åˆ°æœåŠ¡å™¨ä½¿ç”¨åŒæ­¥io
        self._ios[0].script_load(script_text)
        # æ³¨å†Œè„šæœ¬åˆ°å¼‚æ­¥ioï¼Œå› ä¸ºmasteråªèƒ½æœ‰ä¸€ä¸ªè¿æ¥ï¼Œç›´æ¥[0]å°±è¡Œäº†
        return self._async_ios[0].register_script(script_text)  # pyright: ignore[reportAttributeAccessIssue]

    @property
    def io(self) -> redis.Redis | redis.cluster.RedisCluster:
        """éšæœºè¿”å›ä¸€ä¸ªåŒæ­¥è¿æ¥"""
        return random.choice(self._ios)

    @property
    def aio(self):
        """éšæœºè¿”å›ä¸€ä¸ªå¼‚æ­¥è¿æ¥"""
        if self.loop_id == 0:
            self.loop_id = hash(asyncio.get_running_loop())
        # redis-pyçš„async connectionç”¨çš„pythonçš„steam.connectï¼Œç»‘å®šåˆ°å½“å‰åç¨‹
        # è€Œaioæ˜¯ä¸€ä¸ªconnection poolï¼Œæ–­å¼€çš„è¿æ¥ä¼šæ”¾å›poolä¸­ï¼Œæ‰€ä»¥aioä¸èƒ½è·¨åç¨‹ä¼ é€’
        assert hash(asyncio.get_running_loop()) == self.loop_id, (
            "Backendåªèƒ½åœ¨åŒä¸€ä¸ªcoroutineä¸­ä½¿ç”¨ã€‚æ£€æµ‹åˆ°è°ƒç”¨æ­¤å‡½æ•°çš„åç¨‹å‘ç”Ÿäº†å˜åŒ–"
        )

        return random.choice(self._async_ios)

    @staticmethod
    def table_prefix(table_ref: TableReference) -> str:
        """è·å–redisè¡¨åå‰ç¼€"""
        return f"{table_ref.instance_name}:{table_ref.comp_cls.component_name_}"

    @staticmethod
    def cluster_prefix(table_ref: TableReference) -> str:
        """è·å–redisè¡¨åå‰ç¼€"""
        return (
            f"{table_ref.instance_name}:{table_ref.comp_cls.component_name_}:"
            f"{{CLU{table_ref.cluster_id}}}"
        )

    @classmethod
    def row_key(cls, table_ref: TableReference, row_id: str | int) -> str:
        """è·å–redisè¡¨è¡Œçš„keyå"""
        return f"{cls.cluster_prefix(table_ref)}:id:{str(row_id)}"

    @classmethod
    def index_key(cls, table_ref: TableReference, index_name: str) -> str:
        """è·å–redisè¡¨ç´¢å¼•çš„keyå"""
        return f"{cls.cluster_prefix(table_ref)}:index:{index_name}"

    async def reset_async_connection_pool(self):
        """é‡ç½®å¼‚æ­¥è¿æ¥æ± ï¼Œç”¨äºåç¨‹åˆ‡æ¢åï¼Œè§£å†³aioä¸èƒ½è·¨åç¨‹ä¼ é€’çš„é—®é¢˜"""
        self.loop_id = 0
        for aio in self._async_ios:
            if isinstance(aio, redis.asyncio.cluster.RedisCluster):
                await aio.aclose()  # æœªæµ‹è¯•
            else:
                aio.connection_pool.reset()

    # ============ ç»§æ‰¿è‡ªBackendClientçš„æ–¹æ³• ============

    def __init__(self, endpoint: str | list[str], clustering: bool, is_servant=False):
        super().__init__(endpoint, clustering, is_servant)
        # redisçš„endpointé…ç½®ä¸ºurl, æˆ–list of url
        self.urls = [endpoint] if type(endpoint) is str else endpoint
        assert len(self.urls) > 0, "å¿…é¡»è‡³å°‘æŒ‡å®šä¸€ä¸ªæ•°æ®åº“è¿æ¥URL"

        # åˆ›å»ºè¿æ¥
        self._ios: list[redis.Redis | redis.cluster.RedisCluster] = []
        self._async_ios: list[
            redis.asyncio.Redis | redis.asyncio.cluster.RedisCluster
        ] = []
        for url in self.urls:
            if self.clustering:
                self._ios.append(redis.cluster.RedisCluster.from_url(url))
                self._async_ios.append(redis.asyncio.cluster.RedisCluster.from_url(url))
            else:
                self._ios.append(redis.Redis.from_url(url))
                self._async_ios.append(redis.asyncio.Redis.from_url(url))

        # æµ‹è¯•è¿æ¥æ˜¯å¦æ­£å¸¸
        for i, io in enumerate(self._ios):
            try:
                io.ping()
            except redis.exceptions.ConnectionError as e:
                raise ConnectionError(f"æ— æ³•è¿æ¥åˆ°Redisæ•°æ®åº“ï¼š{self.urls[i]}") from e

        # è·å¾—db index
        if self.clustering:
            self.dbi = 0  # é›†ç¾¤æ¨¡å¼æ²¡æœ‰dbçš„æ¦‚å¿µï¼Œé»˜è®¤0
        else:
            io = self._ios[0]
            assert isinstance(io, redis.Redis)  # for type checking
            self.dbi = io.connection_pool.connection_kwargs["db"]

        self.lua_commit = None

        # é™åˆ¶aioè¿è¡Œçš„coroutine
        try:
            self.loop_id = hash(asyncio.get_running_loop())
        except RuntimeError:
            self.loop_id = 0

    @override
    def post_configure(self) -> None:
        """
        å¯¹æ•°æ®åº“åšçš„é…ç½®å·¥ä½œæ”¾åœ¨è¿™ï¼Œå¯ä»¥åšäº›å‡å°‘è¿ç»´å‹åŠ›çš„å·¥ä½œï¼Œæˆ–æ˜¯éœ€è¦é¡¹ç›®åŠ è½½å®Œæˆåæ‰èƒ½åšçš„åˆå§‹åŒ–å·¥ä½œã€‚
        æ­¤é¡¹åœ¨æœåŠ¡å™¨å®Œå…¨åŠ è½½å®Œæ¯•åæ‰ä¼šæ‰§è¡Œï¼Œåœ¨æµ‹è¯•ç¯å¢ƒä¸­ï¼Œä¹Ÿæ˜¯æœ€åè°ƒç”¨ã€‚
        """
        if self.is_servant:
            self.configure_servant()
        else:
            self.configure_master()

    def configure_master(self) -> None:
        if not self._ios:
            raise ConnectionError("è¿æ¥å·²å…³é—­ï¼Œå·²è°ƒç”¨è¿‡close")

        # æ£€æµ‹redisç‰ˆæœ¬
        def parse_version(x):
            return tuple(map(int, x.split(".")))

        for i, io in enumerate(self._ios):
            info: dict = cast(dict, io.info("server"))  # é˜²æ­¢Awaitableç±»å‹æ£€æŸ¥æŠ¥é”™
            redis_ver = parse_version(info["redis_version"])
            assert redis_ver >= (7, 0), "Redis/Valkey ç‰ˆæœ¬è¿‡ä½ï¼Œè‡³å°‘éœ€è¦7.0ç‰ˆæœ¬"

        # åŠ è½½luaè„šæœ¬ï¼Œæ³¨æ„redis-pyçš„pipelineé‡Œä¸èƒ½ç”¨luaï¼Œä¼šåå¤æ£€æµ‹script existsæ€§èƒ½æä½
        self.lua_commit = self.load_commit_scripts(
            Path(__file__).parent.resolve() / "commit.lua"
        )

    def configure_servant(self) -> None:
        if not self._ios:
            raise ConnectionError("è¿æ¥å·²å…³é—­ï¼Œå·²è°ƒç”¨è¿‡close")
            # æ£€æŸ¥servantsè®¾ç½®

        target_keyspace = "Kghz"
        for i, io in enumerate(self._ios):
            try:
                # è®¾ç½®keyspaceé€šçŸ¥ï¼Œå…ˆcasté˜²æ­¢Awaitableç±»å‹æ£€æŸ¥æŠ¥é”™
                notify_config = cast(dict, io.config_get("notify-keyspace-events"))
                db_keyspace = notify_config["notify-keyspace-events"]
                db_keyspace = db_keyspace.replace("A", "g$lshztxed")
                db_keyspace_new = db_keyspace
                for flag in list(target_keyspace):
                    if flag not in db_keyspace:
                        db_keyspace_new += flag
                if db_keyspace_new != db_keyspace:
                    io.config_set("notify-keyspace-events", db_keyspace_new)
            except (
                redis.exceptions.NoPermissionError,
                redis.exceptions.ResponseError,
            ):
                msg = (
                    f"âš ï¸ [ğŸ’¾Redis] æ— æƒé™è°ƒç”¨æ•°æ®åº“{self.urls[i]}çš„config_setå‘½ä»¤ï¼Œæ•°æ®è®¢é˜…å°†"
                    f"ä¸èµ·æ•ˆã€‚å¯æ‰‹åŠ¨è®¾ç½®é…ç½®æ–‡ä»¶ï¼šnotify-keyspace-events={target_keyspace}"
                )
                logger.warning(msg)
            # æ£€æŸ¥æ˜¯å¦æ˜¯replicaæ¨¡å¼
            db_replica = cast(dict, io.config_get("replica-read-only"))
            if db_replica.get("replica-read-only") != "yes":
                msg = (
                    "âš ï¸ [ğŸ’¾Redis] servantå¿…é¡»æ˜¯Read Only Replicaæ¨¡å¼ã€‚"
                    f"{self.urls[i]} æœªè®¾ç½®replica-read-only=yes"
                )
                logger.warning(msg)
                # ä¸æ£€æŸ¥replicaof masteråœ°å€ï¼Œå› ä¸ºreplicaofçš„å¯èƒ½æ˜¯å…¶ä»–replicaåœ°å€
            # è€ƒè™‘å¯ä»¥æ£€æŸ¥pubsub client buffè®¾ç½®ï¼Œçœ‹çœ‹èƒ½å¦rediså´©äº†æé†’ä¸‹
            # pubsubå€¼å»ºè®®ä¸º$å‰©ä½™å†…å­˜/é¢„ä¼°åœ¨çº¿æ•°$

    @override
    async def is_synced(self) -> bool:
        if not self._ios:
            raise ConnectionError("è¿æ¥å·²å…³é—­ï¼Œå·²è°ƒç”¨è¿‡close")

        assert not self.is_servant, "is_syncedåªèƒ½åœ¨masterä¸Šè°ƒç”¨"

        info = await self.aio.info("replication")
        master_offset = int(info.get("master_repl_offset", 0))
        for key, value in info.items():
            # å…¼å®¹ Redis æ–°æ—§ç‰ˆæœ¬ï¼ˆslave/replica å­—æ®µï¼‰
            if key.startswith("slave") or key.startswith("replica"):
                lag_of_offset = master_offset - int(value.get("offset", 0))
                if lag_of_offset > 0:
                    return False
        return True

    @override
    def get_worker_keeper(self, sequence_id: int) -> RedisWorkerKeeper:
        """
        è·å–RedisWorkerKeeperå®ä¾‹ï¼Œç”¨äºé›ªèŠ±IDçš„worker idç®¡ç†ã€‚

        Parameters
        ----------
        sequence_id: int
            å¯åŠ¨è¿›ç¨‹çš„é¡ºåºIDï¼Œä»0å¼€å§‹ã€‚
        """
        assert not self.is_servant, "get_worker_keeper"
        from .worker_keeper import RedisWorkerKeeper

        return RedisWorkerKeeper(sequence_id, self.io, self.aio)

    @override
    async def close(self):
        if not self._ios:
            return

        for io in self._ios:
            io.close()
        self._ios = []

        for aio in self._async_ios:
            await aio.aclose()
        self._async_ios = []

    @staticmethod
    def _row_decode(
        comp_cls: type[BaseComponent], row: dict[bytes, bytes], fmt: RowFormat
    ) -> np.record | dict[str, Any]:
        """å°†redisè·å–çš„è¡Œbyteæ•°æ®è§£ç ä¸ºæŒ‡å®šæ ¼å¼"""
        row_decoded = {
            k.decode("utf-8", "ignore"): v.decode("utf-8", "ignore")
            for k, v in row.items()
        }
        match fmt:
            case RowFormat.RAW:
                return row_decoded
            case RowFormat.STRUCT:
                return comp_cls.dict_to_row(row_decoded)
            case RowFormat.TYPED_DICT:
                struct_row = comp_cls.dict_to_row(row_decoded)
                return comp_cls.row_to_dict(struct_row)
            case _:
                raise ValueError(f"ä¸å¯ç”¨çš„è¡Œæ ¼å¼: {fmt}")

    @overload
    async def get(
        self,
        table_ref: TableReference,
        row_id: int,
        row_format: Literal[RowFormat.STRUCT] = RowFormat.STRUCT,
    ) -> np.record | None: ...
    @overload
    async def get(
        self,
        table_ref: TableReference,
        row_id: int,
        row_format: Literal[RowFormat.RAW] = ...,
    ) -> dict[str, str] | None: ...
    @overload
    async def get(
        self,
        table_ref: TableReference,
        row_id: int,
        row_format: Literal[RowFormat.TYPED_DICT] = ...,
    ) -> dict[str, Any] | None: ...
    @overload
    async def get(
        self,
        table_ref: TableReference,
        row_id: int,
        row_format: RowFormat = ...,
    ) -> np.record | dict[str, str] | dict[str, Any] | None: ...
    @override
    async def get(
        self, table_ref: TableReference, row_id: int, row_format=RowFormat.STRUCT
    ) -> np.record | dict[str, Any] | None:
        """
        ä»æ•°æ®åº“ç›´æ¥è·å–å•è¡Œæ•°æ®ã€‚

        Parameters
        ----------
        table_ref: TableReference
            è¡¨ä¿¡æ¯ï¼ŒæŒ‡å®šComponentã€å®ä¾‹åã€åˆ†ç‰‡ç°‡idã€‚
        row_id: int
            row idä¸»é”®
        row_format
            è¿”å›æ•°æ®è§£ç æ ¼å¼ï¼Œè§ "Returns"

        Returns
        -------
        row: np.record or dict[str, any] or None
            å¦‚æœæœªæŸ¥è¯¢åˆ°åŒ¹é…æ•°æ®ï¼Œåˆ™è¿”å› Noneã€‚
            å¦åˆ™æ ¹æ® `row_format` å‚æ•°è¿”å›ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€ï¼š

            - RowFormat.STRUCT - **é»˜è®¤å€¼**
                è¿”å› np.record (c-struct) çš„å•è¡Œæ•°æ®
            - RowFormat.RAW
                è¿”å›æ— ç±»å‹çš„åŸå§‹æ•°æ® (dict[str, str])
            - RowFormat.TYPED_DICT
                è¿”å›ç¬¦åˆComponentå®šä¹‰çš„ï¼Œæœ‰æ ¼å¼çš„dictç±»å‹ã€‚
        """
        # todo æ‰€æœ‰get queryè¦åˆæ‰¹
        key = self.row_key(table_ref, row_id)
        if row := await self.aio.hgetall(key):  # pyright: ignore[reportGeneralTypeIssues]
            return self._row_decode(table_ref.comp_cls, row, row_format)
        else:
            return None

    @staticmethod
    def _range_normalize(
        is_str_index: bool,
        left: int | float | str | bool,
        right: int | float | str | bool | None,
        desc: bool,
    ) -> tuple[int | float | str, int | float | str]:
        """è§„èŒƒåŒ–èŒƒå›´æŸ¥è¯¢çš„å·¦è¾¹ç•Œå’Œå³è¾¹ç•Œ"""
        if right is None:
            right = left
        if desc:
            left, right = right, left

        # å¯¹äºstrç±»å‹æŸ¥è¯¢ï¼Œè¦ç”¨[å¼€å§‹
        if is_str_index:
            left = str(left)
            right = str(right)
            # åˆ¤æ–­typeæ•ˆç‡å¤ªä½äº†ï¼Œç‰¹åˆ«æ˜¯isinstanceï¼Œå–æ¶ˆæ‰
            # assert (
            #     isinstance(left, (str, np.str_)) and isinstance(right, (str, np.str_))
            # ), f"å­—ç¬¦ä¸²ç±»å‹ç´¢å¼•`{index_name}`çš„æŸ¥è¯¢(left={left}, {type(left)})å˜é‡ç±»å‹å¿…é¡»æ˜¯str"
            if not left.startswith(("(", "[")):
                left = f"[{left}"
            if not right.startswith(("(", "[")):
                right = f"[{right}"

            if not left.endswith((":", ";")):
                left = f"{left}:"  # name:id å½¢å¼ï¼Œæ‰€ä»¥:ä½œä¸ºç»“å°¾æ ‡è¯†ç¬¦
            if not right.endswith((":", ";")):
                right = f"{right};"  # ';' = 3B, ':' = 3A

        return left, right

    @overload
    async def range(
        self,
        table_ref: TableReference,
        index_name: str,
        left: int | float | str | bool,
        right: int | float | str | bool | None = None,
        limit: int = 100,
        desc: bool = False,
        row_format: Literal[RowFormat.STRUCT] = RowFormat.STRUCT,
    ) -> np.recarray: ...
    @overload
    async def range(
        self,
        table_ref: TableReference,
        index_name: str,
        left: int | float | str | bool,
        right: int | float | str | bool | None = None,
        limit: int = 100,
        desc: bool = False,
        row_format: Literal[RowFormat.RAW] = ...,
    ) -> list[dict[str, str]]: ...
    @overload
    async def range(
        self,
        table_ref: TableReference,
        index_name: str,
        left: int | float | str | bool,
        right: int | float | str | bool | None = None,
        limit: int = 100,
        desc: bool = False,
        row_format: Literal[RowFormat.TYPED_DICT] = ...,
    ) -> list[dict[str, Any]]: ...
    @overload
    async def range(
        self,
        table_ref: TableReference,
        index_name: str,
        left: int | float | str | bool,
        right: int | float | str | bool | None = None,
        limit: int = 100,
        desc: bool = False,
        row_format: Literal[RowFormat.ID_LIST] = ...,
    ) -> list[int]: ...
    @overload
    async def range(
        self,
        table_ref: TableReference,
        index_name: str,
        left: int | float | str | bool,
        right: int | float | str | bool | None = None,
        limit: int = 100,
        desc: bool = False,
        row_format: RowFormat = ...,
    ) -> np.recarray | list[dict[str, str]] | list[dict[str, Any]] | list[int]: ...
    @override
    async def range(
        self,
        table_ref: TableReference,
        index_name: str,
        left: int | float | str | bool,
        right: int | float | str | bool | None = None,
        limit: int = 100,
        desc: bool = False,
        row_format=RowFormat.STRUCT,
    ) -> list[int] | list[dict[str, Any]] | np.recarray:
        """
        ä»æ•°æ®åº“ç›´æ¥æŸ¥è¯¢ç´¢å¼• `index_name`ï¼Œè¿”å›åœ¨ [`left`, `right`] é—­åŒºé—´å†…æ•°æ®ã€‚
        å¦‚æœ `right` ä¸º `None`ï¼Œåˆ™æŸ¥è¯¢ç­‰äº `left` çš„æ•°æ®ï¼Œé™åˆ¶ `limit` æ¡ã€‚

        Parameters
        ----------
        table_ref: TableReference
            è¡¨ä¿¡æ¯ï¼ŒæŒ‡å®šComponentã€å®ä¾‹åã€åˆ†ç‰‡ç°‡idã€‚
        index_name: str
            æŸ¥è¯¢Componentä¸­çš„å“ªæ¡ç´¢å¼•
        left, right: str or number
            æŸ¥è¯¢èŒƒå›´ï¼Œé—­åŒºé—´ã€‚å­—ç¬¦ä¸²æŸ¥è¯¢æ—¶ï¼Œå¯ä»¥åœ¨å¼€å¤´æŒ‡å®šæ˜¯[é—­åŒºé—´ï¼Œè¿˜æ˜¯(å¼€åŒºé—´ã€‚
            å¦‚æœrightä¸å¡«å†™ï¼Œåˆ™ç²¾ç¡®æŸ¥è¯¢ç­‰äºleftçš„æ•°æ®ã€‚
        limit: int
            é™åˆ¶è¿”å›çš„è¡Œæ•°ï¼Œè¶Šå°‘è¶Šå¿«
        desc: bool
            æ˜¯å¦é™åºæ’åˆ—
        row_format
            è¿”å›æ•°æ®è§£ç æ ¼å¼ï¼Œè§ "Returns"

        Returns
        -------
        row: np.recarray or list[id] or list[dict]
            æ ¹æ® `row_format` å‚æ•°è¿”å›ä»¥ä¸‹æ ¼å¼ä¹‹ä¸€ï¼š

            - RowFormat.STRUCT - **é»˜è®¤å€¼**
                è¿”å› `numpy.recarray`ï¼Œå¦‚æœæ²¡æœ‰æŸ¥è¯¢åˆ°æ•°æ®ï¼Œè¿”å›ç©º `numpy.recarray`ã€‚
                `numpy.recarray` æ˜¯ä¸€ç§ c-struct arrayã€‚
            - RowFormat.RAW
                è¿”å›æ— ç±»å‹çš„åŸå§‹æ•°æ® (dict[str, str]) åˆ—è¡¨ï¼Œå¦‚æœæ²¡æœ‰æŸ¥è¯¢åˆ°æ•°æ®ï¼Œè¿”å›ç©ºlist
            - RowFormat.TYPED_DICT
                è¿”å›ç¬¦åˆComponentå®šä¹‰çš„ï¼Œæœ‰æ ¼å¼çš„dictç±»å‹åˆ—è¡¨ï¼Œå¦‚æœæ²¡æœ‰æŸ¥è¯¢åˆ°æ•°æ®ï¼Œè¿”å›ç©ºlist
            - RowFormat.ID_LIST
                è¿”å›æŸ¥è¯¢åˆ°çš„ row id åˆ—è¡¨ï¼Œå¦‚æœæ²¡æœ‰æŸ¥è¯¢åˆ°æ•°æ®ï¼Œè¿”å›ç©ºlist

        Notes
        -----
        å¦‚ä½•å¤åˆæ¡ä»¶æŸ¥è¯¢ï¼Ÿ
        è¯·åˆ©ç”¨pythonçš„ç‰¹æ€§ï¼Œå…ˆåœ¨æ•°æ®åº“ä¸Šç­›é€‰å‡ºæœ€å°‘é‡çš„æ•°æ®ï¼Œç„¶åæœ¬åœ°äºŒæ¬¡ç­›é€‰::

            items = client.range(ref, "owner", player_id, limit=100)
            few_items = items[items.amount < 10]

        ç”±äºpython numpyæ”¯æŒSIMDï¼Œæ¯”ç›´æ¥åœ¨æ•°æ®åº“å¤åˆæŸ¥è¯¢å¿«ã€‚
        """
        # todo æ‰€æœ‰get queryè¦åˆæ‰¹
        idx_key = self.index_key(table_ref, index_name)
        aio = self.aio  # ä¿å­˜éšæœºé€‰ä¸­çš„aioè¿æ¥

        # ç”Ÿæˆzrangeå‘½ä»¤
        comp_cls = table_ref.comp_cls
        is_str_index = comp_cls.indexes_[index_name]
        left, right = self._range_normalize(
            is_str_index,
            left,
            right,
            desc,
        )

        # å¯¹äºstrç±»å‹æŸ¥è¯¢ï¼Œè¦ç”¨bylex
        by_lex = True if is_str_index else False
        cmds = {
            "start": left,
            "end": right,
            "desc": desc,
            "offset": 0,
            "num": limit,
            "bylex": by_lex,
            "byscore": not by_lex,
        }

        row_ids = await aio.zrange(name=idx_key, **cmds)
        if is_str_index:
            row_ids = [
                int(vk.decode("utf-8", "ignore").split(":")[-1]) for vk in row_ids
            ]
        else:
            row_ids = list(map(int, row_ids))

        if row_format == RowFormat.ID_LIST:
            return row_ids

        key_prefix = self.cluster_prefix(table_ref) + ":id:"  # å­˜ä¸‹å‰ç¼€ç»„åˆkeyå¿«1å€
        rows = []
        for _id in row_ids:
            # todo è¦ä¹ˆç”¨åˆæ‰¹çš„è¯·æ±‚æ–¹æ³•ï¼Œè¦ä¹ˆç”¨pipeline
            if row := await aio.hgetall(key_prefix + str(_id)):  # pyright: ignore[reportGeneralTypeIssues]
                rows.append(self._row_decode(comp_cls, row, row_format))

        if row_format == RowFormat.RAW or row_format == RowFormat.TYPED_DICT:
            return cast(list[dict[str, Any]], rows)
        else:
            if len(rows) == 0:
                return np.rec.array(np.empty(0, dtype=comp_cls.dtypes))
            else:
                record_list = cast(list[np.record], rows)
                return np.rec.array(np.stack(record_list, dtype=comp_cls.dtypes))

    @override
    async def commit(self, idmap: IdentityMap) -> None:
        """
        ä½¿ç”¨äº‹åŠ¡ï¼Œå‘æ•°æ®åº“æäº¤IdentityMapä¸­çš„æ‰€æœ‰æ•°æ®ä¿®æ”¹

        Exceptions
        --------
        RaceCondition
            å½“æäº¤æ•°æ®æ—¶ï¼Œå‘ç°æ•°æ®å·²è¢«å…¶ä»–äº‹åŠ¡ä¿®æ”¹ï¼ŒæŠ›å‡ºæ­¤å¼‚å¸¸

        """
        assert not self.is_servant, "ä»èŠ‚ç‚¹ä¸å…è®¸æäº¤äº‹åŠ¡"

        dirty_rows = idmap.get_dirty_rows()
        assert len(dirty_rows) > 0, "æ²¡æœ‰è„æ•°æ®éœ€è¦æäº¤"

        ref = idmap.first_reference()
        assert ref is not None, "ä¸è¯¥èµ°åˆ°è¿™é‡Œï¼Œä»…ç”¨äºtypingæ£€æŸ¥"

        # è½¬æ¢dirty_rowsä¸ºçº¯luaå¯ç”¨çš„ä¿¡æ¯æ ¼å¼ï¼š
        # payload={"insert": {"instance:TableName:{CLU1}": [row_dict, ...]}...}
        # todo å°è¯•ç»„åˆæˆchecks/setså‘½ä»¤è¡¨ï¼Œå‡å°‘luaè„šæœ¬çš„å¤æ‚åº¦
        #      checksæœ‰exists/unique/version
        #      setsæœ‰hmset/zadd/zrem/del
        payload = {
            commit_type: {
                self.cluster_prefix(ref): rows for ref, rows in commit_data.items()
            }
            for commit_type, commit_data in dirty_rows.items()
        }
        payload_json = msgpack.encode(payload)
        # æ·»åŠ ä¸€ä¸ªå¸¦cluster idçš„keyï¼ŒæŒ‡æ˜luaè„šæœ¬æ‰§è¡Œçš„é›†ç¾¤
        keys = [self.row_key(ref, 1)]

        # è¿™é‡Œä¸éœ€è¦åˆ¤æ–­redis.exceptions.NoScriptErrorï¼Œå› ä¸ºé‡Œé¢ä¼šå¤„ç†
        assert self.lua_commit is not None, "typingæ£€æŸ¥, å¯å¿½ç•¥"
        resp = await self.lua_commit(keys, [payload_json])
        resp = resp.decode("utf-8")  # pyright: ignore[reportAttributeAccessIssue]

        if resp != "committed":
            if resp.startswith("RACE"):
                raise RaceCondition(resp)
            elif resp.startswith("UNIQUE"):
                # uniqueè¿åå°±æ˜¯indexçš„ç«æ€åŸå› 
                raise RaceCondition(resp)
            else:
                raise RuntimeError(f"æœªçŸ¥çš„æäº¤é”™è¯¯ï¼š{resp}")

    def get_table_maintenance(self) -> RedisTableMaintenance:
        """
        è·å–è¡¨ç»´æŠ¤å¯¹è±¡ã€‚
        """
        from .maint import RedisTableMaintenance

        return RedisTableMaintenance(self)
