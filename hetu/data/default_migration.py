import numpy as np
from hetu import BaseComponent
import logging

from hetu.data.backend import TableReference
from hetu.data.backend.base import TableMaintenance

logger = logging.getLogger("HeTu.root")

down_model_json = r"<DOWN_JSON>"
target_model_json = r"<TARGET_JSON>"
# è®¾ç½®å¯¼å‡ºæ¨¡å—å˜é‡ï¼Œè¡¨ç¤ºè¿ç§»çš„æºå’Œç›®æ ‡æ¨¡å‹
TARGET_MODEL = BaseComponent.load_json(target_model_json)
DOWN_MODEL = BaseComponent.load_json(down_model_json)


# é»˜è®¤è¿ç§»è„šæœ¬ç”¨å˜é‡
remove_columns = []
add_columns = []
unsafe_convert_columns = []
type_convert_columns = []


def prepare() -> str:
    """
    è¿ç§»å‰çš„é¢„æ£€æŸ¥ï¼Œæ­¤æ–¹æ³•ä¼šåœ¨upgradeå‰å¤šæ¬¡è°ƒç”¨ï¼Œå¿…é¡»å¹‚ç­‰ã€‚

    Returns
    -------
    str
        - "skip": ç»„ä»¶è¡¨ç»“æ„æ— å˜æ›´ï¼Œæ— éœ€è¿ç§»ã€‚
        - "unsafe": æœ¬è¿ç§»ä»£ç æ˜¯æœ‰æŸè¿ç§»ï¼Œéœ€è¦ç”¨forceæŒ‡ä»¤æ‰‹åŠ¨è¿ç§»ã€‚
        - "ok": å¯ä»¥å®‰å…¨è¿ç§»ã€‚
    """
    name = TARGET_MODEL.component_name_
    # æ£€æŸ¥æ˜¯å¦æ— å˜æ›´
    down_dtypes = DOWN_MODEL.dtypes
    target_dtypes = TARGET_MODEL.dtypes
    if down_dtypes == target_dtypes:
        return "skip"

    logger.warning(
        f"  âš ï¸ [ğŸ’¾Redis][{name}ç»„ä»¶] ä»£ç å®šä¹‰çš„Schemaä¸å·²å­˜çš„ä¸ä¸€è‡´ï¼Œ"
        f"æ•°æ®åº“ä¸­ï¼š\n"
        f"{down_dtypes}\n"
        f"ä»£ç å®šä¹‰çš„ï¼š\n"
        f"{target_dtypes}\n "
        f"å°†å°è¯•æ•°æ®è¿ç§»ï¼ˆåªå¤„ç†æ–°å±æ€§ï¼Œä¸å¤„ç†ç±»å‹å˜æ›´ï¼Œæ”¹åç­‰ç­‰æƒ…å†µï¼‰ï¼š"
    )

    # å‡†å¤‡åˆ—æ£€æŸ¥
    assert down_dtypes.fields and target_dtypes.fields  # for type checker
    down_columns = down_dtypes.fields
    target_columns = target_dtypes.fields

    # æ£€æŸ¥æ˜¯å¦æœ‰å±æ€§è¢«åˆ é™¤
    for down_column in down_columns:
        if down_column not in target_columns:
            msg = (
                f"  âš ï¸ [ğŸ’¾Redis][{name}ç»„ä»¶] "
                f"æ•°æ®åº“ä¸­çš„å±æ€§ {down_column} åœ¨æ–°çš„ç»„ä»¶å®šä¹‰ä¸­ä¸å­˜åœ¨ï¼Œå¦‚æœæ”¹åäº†éœ€è¦æ‰‹åŠ¨è¿ç§»ï¼Œ"
                f"å¼ºåˆ¶æ‰§è¡Œå°†ä¸¢å¼ƒè¯¥å±æ€§æ•°æ®ã€‚"
            )
            logger.warning(msg)
            remove_columns.append(down_column)

    # æ£€æŸ¥æ˜¯å¦æœ‰å±æ€§ç±»å‹å˜æ›´ä¸”æ— æ³•è‡ªåŠ¨è½¬æ¢
    for target_column in target_columns:
        if target_column in down_columns:
            old_type = down_dtypes.fields[target_column]
            new_type = target_dtypes.fields[target_column]
            if old_type != new_type:
                type_convert_columns.append(target_column)
                if not np.can_cast(old_type[0], new_type[0]):
                    msg = (
                        f"  âš ï¸ [ğŸ’¾Redis][{name}ç»„ä»¶] "
                        f"å±æ€§ {target_column} çš„ç±»å‹ç”± {old_type} å˜æ›´ä¸º {new_type}ï¼Œ"
                        f"æ— æ³•è‡ªåŠ¨è½¬æ¢ç±»å‹ï¼Œéœ€è¦æ‰‹åŠ¨è¿ç§»ï¼Œå¼ºåˆ¶æ‰§è¡Œå°†æˆªæ–­/ä¸¢å¼ƒè¯¥å±æ€§æ•°æ®ã€‚"
                    )
                    logger.warning(msg)
                    unsafe_convert_columns.append(target_column)

    # æ£€æŸ¥æ–°å¢çš„å±æ€§æ˜¯å¦æœ‰é»˜è®¤å€¼
    # todo nullableå±æ€§çš„å¤„ç†
    target_props = dict(TARGET_MODEL.properties_)
    for target_column in target_columns:
        if target_column not in down_columns:
            add_columns.append(target_column)
            logger.warning(
                f"  âš ï¸ [ğŸ’¾Redis][{name}ç»„ä»¶] "
                f"æ–°çš„ä»£ç å®šä¹‰ä¸­å¤šå‡ºå±æ€§ {target_column}ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼å¡«å……ã€‚"
            )
            default = target_props[target_column].default
            if default is None:
                msg = (
                    f"  âš ï¸ [ğŸ’¾Redis][{name}ç»„ä»¶] "
                    f"è¿ç§»æ—¶å°è¯•æ–°å¢ {target_column} å±æ€§å¤±è´¥ï¼Œè¯¥å±æ€§æ²¡æœ‰é»˜è®¤å€¼ï¼Œæ— æ³•æ–°å¢ã€‚"
                )
                logger.error(msg)
                raise ValueError(msg)

    if remove_columns or unsafe_convert_columns:
        return "unsafe"

    return "ok"


def upgrade(
    row_ids: list[int],
    table_refs: dict[type[BaseComponent], TableReference],
    client: TableMaintenance.MaintenanceClient,  # è´Ÿè´£ç›´æ¥å†™å…¥æ•°æ®çš„ï¼Œä¸“ä¾›è¿ç§»ä½¿ç”¨çš„å®¢æˆ·ç«¯
) -> None:
    # ä¸€äº›å±æ€§ä¿¡æ¯
    from_dtypes = DOWN_MODEL.dtypes
    target_dtypes = TARGET_MODEL.dtypes
    target_columns = dict(TARGET_MODEL.properties_)
    assert from_dtypes.fields and target_dtypes.fields  # for type checker

    # å¼€å§‹schemaè¿ç§»
    # è¿ç§»åˆ é™¤çš„åˆ—
    for col in remove_columns:
        client.remove_column(table_refs[DOWN_MODEL], col)
    # è¿ç§»å¢åŠ çš„åˆ—
    for col in add_columns:
        client.add_column(table_refs[DOWN_MODEL], col, target_columns[col].dtype)
    # è¿ç§»ç±»å‹å˜æ›´çš„åˆ—
    for col in type_convert_columns:
        client.add_column(
            table_refs[DOWN_MODEL], col + "__temp__", target_columns[col].dtype
        )

    added = 0
    converted = 0
    convert_failed = 0
    for row_id in row_ids:
        up_row = client.get(table_refs[DOWN_MODEL], row_id)
        assert up_row

        # å¦‚æœæœ‰æ–°å¢åˆ—ï¼Œéœ€è¦updateæ•´ä¸ªrow(compè‡ªåŠ¨å¸¦é»˜è®¤å€¼)
        # å¦‚æœæœ‰åˆ é™¤åˆ—ï¼Œä¹Ÿupdateæ•´ä¸ªrow(clientè‡ªåŠ¨del then update)
        # å¦‚æœæœ‰ç±»å‹å˜æ›´ï¼Œä¹Ÿupdateæ•´ä¸ªrow(clientåœ¨getæ—¶å·²è‡ªåŠ¨ç±»å‹æ›´æ–°äº†)
        client.update(table_refs[DOWN_MODEL], up_row)
        # è¿ç§»åˆ é™¤çš„åˆ—

    # åˆ é™¤ç±»å‹å˜æ›´çš„ä¸´æ—¶åˆ—
    for col in type_convert_columns:
        client.remove_column(table_refs[DOWN_MODEL], col + "__temp__")
    ###########################################

    for prop_name in target_dtypes.fields:
        # todo åˆ é™¤çš„å±æ€§ç›®å‰ä¼šé—ç•™åœ¨redisä¸­
        if prop_name not in from_dtypes.fields:
            default = target_props[prop_name].default
            pipe = io.pipeline()
            for key in keys:
                pipe.hset(key.decode(), prop_name, default)
            pipe.execute()
            added += 1
        elif force:  # ç±»å‹è½¬æ¢
            old_type = from_dtypes.fields[prop_name][0]
            new_type = target_dtypes.fields[prop_name][0]
            if old_type == new_type:
                continue
            default = props[prop_name].default
            pipe = io.pipeline()
            for key in keys:
                val = io.hget(key.decode(), prop_name)
                if val is None:
                    continue
                try:
                    val = cast(bytes, cast(object, val))
                    casted_val = new_type.type(old_type.type(val.decode()))

                    if np.issubdtype(new_type, np.character):
                        # å­—ç¬¦ä¸²ç±»å‹éœ€è¦ç‰¹æ®Šæˆªæ–­å¤„ç†ï¼Œä¸ç„¶npä¼šè‡ªåŠ¨å»¶é•¿
                        def fixed_str_len(dt: np.dtype) -> int:
                            dt = np.dtype(dt)
                            if dt.kind == "U":
                                return dt.itemsize // 4
                            if dt.kind == "S":
                                return dt.itemsize
                            raise TypeError(f"not a fixed-length string dtype: {dt!r}")

                        casted_val = casted_val[: fixed_str_len(new_type)]

                    pipe.hset(key.decode(), prop_name, str(casted_val))
                    converted += 1
                except ValueError as _:
                    # å¼ºåˆ¶æ¨¡å¼ä¸‹ä¸¢å¼ƒè¯¥å±æ€§
                    pipe.hset(key.decode(), prop_name, default)
                    convert_failed += 1
            pipe.execute()

    # æ›´æ–°meta
    version = hashlib.md5(table_ref.comp_cls.json_.encode("utf-8")).hexdigest()
    io.hset(self.meta_key(table_ref), "version", version)
    io.hset(self.meta_key(table_ref), "json", table_ref.comp_cls.json_)

    logger.warning(
        f"  âœ”ï¸ [ğŸ’¾Redis][{table_ref.comp_name}ç»„ä»¶] æ–°å±æ€§å¢åŠ å®Œæˆï¼Œå…±å¤„ç†{len(keys)}è¡Œ * "
        f"{added}ä¸ªå±æ€§ã€‚ è½¬æ¢ç±»å‹æˆåŠŸ{converted}æ¬¡ï¼Œå¤±è´¥{convert_failed}æ¬¡ã€‚"
    )
    return True
