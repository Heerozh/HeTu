import numpy as np
from hetu import BaseComponent
import logging

from hetu.data.backend import TableReference
from hetu.data.backend.base import TableMaintenance

logger = logging.getLogger("HeTu.root")

down_model_json = r"<DOWN_JSON>"
target_model_json = r"<TARGET_JSON>"
# ËÆæÁΩÆÂØºÂá∫Ê®°ÂùóÂèòÈáèÔºåË°®Á§∫ËøÅÁßªÁöÑÊ∫êÂíåÁõÆÊ†áÊ®°Âûã
TARGET_MODEL = BaseComponent.load_json(target_model_json)
DOWN_MODEL = BaseComponent.load_json(down_model_json)


# ÈªòËÆ§ËøÅÁßªËÑöÊú¨Áî®ÂèòÈáè
remove_columns = []
add_columns = []
unsafe_convert_columns = []
type_convert_columns = []


def prepare() -> str:
    """
    ËøÅÁßªÂâçÁöÑÈ¢ÑÊ£ÄÊü•ÔºåÂ¶ÇÊûú‰∏çËÉΩËøÅÁßªÂú®ËøôÊä•Èîô„ÄÇ
    Ê≠§ÊñπÊ≥ï‰ºöÂú®upgradeÂâçÂ§öÊ¨°Ë∞ÉÁî®ÔºåÂøÖÈ°ªÂπÇÁ≠â„ÄÇ

    Returns
    -------
    str
        - "skip": ÁªÑ‰ª∂Ë°®ÁªìÊûÑÊó†ÂèòÊõ¥ÔºåÊó†ÈúÄËøÅÁßª„ÄÇ
        - "unsafe": Êú¨ËøÅÁßª‰ª£Á†ÅÊòØÊúâÊçüËøÅÁßªÔºåÈúÄË¶ÅÁî®forceÊåá‰ª§ÊâãÂä®ËøÅÁßª„ÄÇ
        - "ok": ÂèØ‰ª•ÂÆâÂÖ®ËøÅÁßª„ÄÇ
    """
    name = TARGET_MODEL.component_name_
    # Ê£ÄÊü•ÊòØÂê¶Êó†ÂèòÊõ¥
    down_dtypes = DOWN_MODEL.dtypes
    target_dtypes = TARGET_MODEL.dtypes
    if down_dtypes == target_dtypes:
        return "skip"

    logger.warning(
        f"  ‚ö†Ô∏è [üíæRedis][{name}ÁªÑ‰ª∂] ‰ª£Á†ÅÂÆö‰πâÁöÑSchema‰∏éÂ∑≤Â≠òÁöÑ‰∏ç‰∏ÄËá¥Ôºå"
        f"Êï∞ÊçÆÂ∫ì‰∏≠Ôºö\n"
        f"{down_dtypes}\n"
        f"‰ª£Á†ÅÂÆö‰πâÁöÑÔºö\n"
        f"{target_dtypes}\n "
        f"Â∞ÜÂ∞ùËØïÊï∞ÊçÆËøÅÁßªÔºàÂè™Â§ÑÁêÜÊñ∞Â±ûÊÄßÔºå‰∏çÂ§ÑÁêÜÁ±ªÂûãÂèòÊõ¥ÔºåÊîπÂêçÁ≠âÁ≠âÊÉÖÂÜµÔºâÔºö"
    )

    # ÂáÜÂ§áÂàóÊ£ÄÊü•
    assert down_dtypes.fields and target_dtypes.fields  # for type checker
    down_columns = down_dtypes.fields
    target_columns = target_dtypes.fields

    # Ê£ÄÊü•ÊòØÂê¶ÊúâÂ±ûÊÄßË¢´Âà†Èô§
    for down_column in down_columns:
        if down_column not in target_columns:
            msg = (
                f"  ‚ö†Ô∏è [üíæRedis][{name}ÁªÑ‰ª∂] "
                f"Êï∞ÊçÆÂ∫ì‰∏≠ÁöÑÂ±ûÊÄß {down_column} Âú®Êñ∞ÁöÑÁªÑ‰ª∂ÂÆö‰πâ‰∏≠‰∏çÂ≠òÂú®ÔºåÂ¶ÇÊûúÊîπÂêç‰∫ÜÈúÄË¶ÅÊâãÂä®ËøÅÁßªÔºå"
                f"Âº∫Âà∂ÊâßË°åÂ∞Ü‰∏¢ÂºÉËØ•Â±ûÊÄßÊï∞ÊçÆ„ÄÇ"
            )
            logger.warning(msg)
            remove_columns.append(down_column)

    # Ê£ÄÊü•ÊòØÂê¶ÊúâÂ±ûÊÄßÁ±ªÂûãÂèòÊõ¥‰∏îÊó†Ê≥ïËá™Âä®ËΩ¨Êç¢
    for target_column in target_columns:
        if target_column in down_columns:
            old_type = down_dtypes.fields[target_column]
            new_type = target_dtypes.fields[target_column]
            if old_type != new_type:
                type_convert_columns.append(target_column)
                if not np.can_cast(old_type[0], new_type[0]):
                    msg = (
                        f"  ‚ö†Ô∏è [üíæRedis][{name}ÁªÑ‰ª∂] "
                        f"Â±ûÊÄß {target_column} ÁöÑÁ±ªÂûãÁî± {old_type} ÂèòÊõ¥‰∏∫ {new_type}Ôºå"
                        f"Êó†Ê≥ïËá™Âä®ËΩ¨Êç¢Á±ªÂûãÔºåÈúÄË¶ÅÊâãÂä®ËøÅÁßªÔºåÂº∫Âà∂ÊâßË°åÂ∞ÜÊà™Êñ≠/‰∏¢ÂºÉËØ•Â±ûÊÄßÊï∞ÊçÆ„ÄÇ"
                    )
                    logger.warning(msg)
                    unsafe_convert_columns.append(target_column)

    # Ê£ÄÊü•Êñ∞Â¢ûÁöÑÂ±ûÊÄßÊòØÂê¶ÊúâÈªòËÆ§ÂÄº
    # todo nullableÂ±ûÊÄßÁöÑÂ§ÑÁêÜ
    target_props = dict(TARGET_MODEL.properties_)
    for target_column in target_columns:
        if target_column not in down_columns:
            add_columns.append(target_column)
            logger.warning(
                f"  ‚ö†Ô∏è [üíæRedis][{name}ÁªÑ‰ª∂] "
                f"Êñ∞ÁöÑ‰ª£Á†ÅÂÆö‰πâ‰∏≠Â§öÂá∫Â±ûÊÄß {target_column}ÔºåÂ∞Ü‰ΩøÁî®ÈªòËÆ§ÂÄºÂ°´ÂÖÖ„ÄÇ"
            )
            default = target_props[target_column].default
            if default is None:
                msg = (
                    f"  ‚ö†Ô∏è [üíæRedis][{name}ÁªÑ‰ª∂] "
                    f"ËøÅÁßªÊó∂Â∞ùËØïÊñ∞Â¢û {target_column} Â±ûÊÄßÂ§±Ë¥•ÔºåËØ•Â±ûÊÄßÊ≤°ÊúâÈªòËÆ§ÂÄºÔºåÊó†Ê≥ïÊñ∞Â¢û„ÄÇ"
                )
                logger.error(msg)
                raise ValueError(msg)

    if remove_columns or unsafe_convert_columns:
        return "unsafe"

    return "ok"


def upgrade(
    row_ids: list[int],
    down_tables: dict[str, TableReference],
    target_table: TableReference,
    client: TableMaintenance.MaintenanceClient,  # Ë¥üË¥£Áõ¥Êé•ÂÜôÂÖ•Êï∞ÊçÆÁöÑÔºå‰∏ì‰æõËøÅÁßª‰ΩøÁî®ÁöÑÂÆ¢Êà∑Á´Ø
) -> None:
    """ÂÆûÈôÖÊâßË°åÂçáÁ∫ßËøÅÁßªÁöÑÊìç‰ΩúÔºåÊú¨Êìç‰Ωú‰∏çÂèØÂ§±Ë¥•„ÄÇ"""
    # ‰∏Ä‰∫õÂ±ûÊÄß‰ø°ÊÅØ
    assert DOWN_MODEL.component_name_ == TARGET_MODEL.component_name_
    table_name = DOWN_MODEL.component_name_
    target_columns = dict(TARGET_MODEL.properties_)

    # ‰øÆÊîπËÄÅÁöÑtableÂêç, ËÄÅÁöÑË°®ËØªÂÆåÂêéÂ∞±Âà†Èô§
    renamed_down_tbl = client.rename_table(down_tables[table_name])
    # ÂàõÂª∫Ë°®ÔºåÂºÄÂßãschemaËøÅÁßª
    client.create_table(target_table)

    for row_id in row_ids:
        down_row = client.get(renamed_down_tbl, row_id)
        assert down_row

        up_row = TARGET_MODEL.empty_row_()

        # Â§çÂà∂ÂéüÊúâÂàó
        for col in target_columns:
            up_row[col] = down_row[col]

        # Â¶ÇÊûúÊúâÊñ∞Â¢ûÂàóÔºå‰∏çÁî®ÁÆ°Ôºåempty_row_Â∑≤ÁªèËá™Âä®Â°´ÂÖÖ‰∫ÜÈªòËÆ§ÂÄº
        # Â¶ÇÊûúÊúâÂà†Èô§ÂàóÔºå‰∏çÁî®ÁÆ°Ôºåup_rowÂ∑≤Áªè‰∏çÂåÖÂê´‰∫Ü
        # Â¶ÇÊûúÊúâÁ±ªÂûãÂèòÊõ¥Ôºå‰πü‰∏çÁî®ÁÆ°ÔºåÂâçÈù¢Âú®Â§çÂà∂ÂéüÊúâÂàóÊó∂Ëá™Âä®ÂÆåÊàê‰∫Ü

        client.upsert(down_tables[table_name], up_row)

    # Âà†Èô§Á±ªÂûãÂèòÊõ¥ÁöÑ‰∏¥Êó∂Âàó
    client.drop_table(renamed_down_tbl)

    # Êõ¥Êñ∞meta
    # version = hashlib.md5(table_ref.comp_cls.json_.encode("utf-8")).hexdigest()
    # io.hset(self.meta_key(table_ref), "version", version)
    # io.hset(self.meta_key(table_ref), "json", table_ref.comp_cls.json_)

    logger.warning(
        f"  ‚úîÔ∏è [üíæRedis][{TARGET_MODEL.component_name_}ÁªÑ‰ª∂] Êñ∞Â±ûÊÄßÂ¢ûÂä†ÂÆåÊàêÔºåÂÖ±Â§ÑÁêÜ{len(row_ids)}Ë°å"
    )


"""
    for prop_name in target_dtypes.fields:
        # todo Âà†Èô§ÁöÑÂ±ûÊÄßÁõÆÂâç‰ºöÈÅóÁïôÂú®redis‰∏≠
        if prop_name not in from_dtypes.fields:
            default = target_props[prop_name].default
            pipe = io.pipeline()
            for key in keys:
                pipe.hset(key.decode(), prop_name, default)
            pipe.execute()
            added += 1
        elif force:  # Á±ªÂûãËΩ¨Êç¢
            old_type = from_dtypes.fields[prop_name][0]
            new_type = target_dtypes.fields[prop_name][0]
            if old_type == new_type:
                continue
            default = props[prop_name].default
            pipe = io.pipeline()
            for key in keys:
                val = io.hget(key.decode(), prop_name)
                if val is None:
                    continue
                try:
                    val = cast(bytes, cast(object, val))
                    casted_val = new_type.type(old_type.type(val.decode()))

                    if np.issubdtype(new_type, np.character):
                        # Â≠óÁ¨¶‰∏≤Á±ªÂûãÈúÄË¶ÅÁâπÊÆäÊà™Êñ≠Â§ÑÁêÜÔºå‰∏çÁÑ∂np‰ºöËá™Âä®Âª∂Èïø
                        def fixed_str_len(dt: np.dtype) -> int:
                            dt = np.dtype(dt)
                            if dt.kind == "U":
                                return dt.itemsize // 4
                            if dt.kind == "S":
                                return dt.itemsize
                            raise TypeError(f"not a fixed-length string dtype: {dt!r}")

                        casted_val = casted_val[: fixed_str_len(new_type)]

                    pipe.hset(key.decode(), prop_name, str(casted_val))
                    converted += 1
                except ValueError as _:
                    # Âº∫Âà∂Ê®°Âºè‰∏ã‰∏¢ÂºÉËØ•Â±ûÊÄß
                    pipe.hset(key.decode(), prop_name, default)
                    convert_failed += 1
            pipe.execute()

    return True
"""
