import logging

import numpy as np

from hetu import BaseComponent
from hetu.data.backend import TableReference
from hetu.data.backend.base import TableMaintenance

logger = logging.getLogger("HeTu.root")

down_component_json = r'<"DOWN_JSON">'
target_component_json = r'<"TARGET_JSON">'
# è®¾ç½®å¯¼å‡ºæ¨¡å—å˜é‡ï¼Œè¡¨ç¤ºè¿ç§»çš„æºå’Œç›®æ ‡æ¨¡å‹
TARGET_COMPONENT_MODEL = BaseComponent.load_json(target_component_json)
DOWN_COMPONENT_MODEL = BaseComponent.load_json(down_component_json)


# é»˜è®¤è¿ç§»è„šæœ¬ç”¨å˜é‡
remove_columns = []
add_columns = []
unsafe_convert_columns = []
type_convert_columns = []


def prepare() -> str:
    """
    è¿ç§»å‰çš„é¢„æ£€æŸ¥ï¼Œå¦‚æœä¸èƒ½è¿ç§»åœ¨è¿™æŠ¥é”™ã€‚
    æ­¤æ–¹æ³•ä¼šåœ¨upgradeå‰å¤šæ¬¡è°ƒç”¨ï¼Œå¿…é¡»å¹‚ç­‰ã€‚

    Returns
    -------
    str
        - "skip": ç»„ä»¶è¡¨ç»“æ„æ— å˜æ›´ï¼Œæ— éœ€è¿ç§»ã€‚
        - "unsafe": æœ¬è¿ç§»ä»£ç æ˜¯æœ‰æŸè¿ç§»ï¼Œéœ€è¦ç”¨forceæŒ‡ä»¤æ‰‹åŠ¨è¿ç§»ã€‚
        - "ok": å¯ä»¥å®‰å…¨è¿ç§»ã€‚
    """
    name = TARGET_COMPONENT_MODEL.component_name_
    # æ£€æŸ¥æ˜¯å¦æ— å˜æ›´
    down_dtypes = DOWN_COMPONENT_MODEL.dtypes
    target_dtypes = TARGET_COMPONENT_MODEL.dtypes
    if down_dtypes == target_dtypes:
        return "skip"

    logger.warning(
        f"  âš ï¸ [ğŸ’¾Redis][{name}ç»„ä»¶] ä»£ç å®šä¹‰çš„Schemaä¸å·²å­˜çš„ä¸ä¸€è‡´ï¼Œ"
        f"æ•°æ®åº“ä¸­ï¼š\n"
        f"{down_dtypes}\n"
        f"ä»£ç å®šä¹‰çš„ï¼š\n"
        f"{target_dtypes}\n "
        f"å°†å°è¯•æ•°æ®è¿ç§»ï¼ˆåªå¤„ç†æ–°å±æ€§ï¼Œä¸å¤„ç†ç±»å‹å˜æ›´ï¼Œæ”¹åç­‰ç­‰æƒ…å†µï¼‰ï¼š"
    )

    # å‡†å¤‡åˆ—æ£€æŸ¥
    assert down_dtypes.fields and target_dtypes.fields  # for type checker
    down_columns = down_dtypes.fields
    target_columns = target_dtypes.fields

    # æ£€æŸ¥æ˜¯å¦æœ‰å±æ€§è¢«åˆ é™¤
    for down_column in down_columns:
        if down_column not in target_columns:
            msg = (
                f"  âš ï¸ [ğŸ’¾Redis][{name}ç»„ä»¶] "
                f"æ•°æ®åº“ä¸­çš„å±æ€§ {down_column} åœ¨æ–°çš„ç»„ä»¶å®šä¹‰ä¸­ä¸å­˜åœ¨ï¼Œå¦‚æœæ”¹åäº†éœ€è¦æ‰‹åŠ¨è¿ç§»ï¼Œ"
                f"å¼ºåˆ¶æ‰§è¡Œå°†ä¸¢å¼ƒè¯¥å±æ€§æ•°æ®ã€‚"
            )
            logger.warning(msg)
            remove_columns.append(down_column)

    # æ£€æŸ¥æ˜¯å¦æœ‰å±æ€§ç±»å‹å˜æ›´ä¸”æ— æ³•è‡ªåŠ¨è½¬æ¢
    for target_column in target_columns:
        if target_column in down_columns:
            old_type = down_dtypes.fields[target_column]
            new_type = target_dtypes.fields[target_column]
            if old_type != new_type:
                type_convert_columns.append(target_column)
                if not np.can_cast(old_type[0], new_type[0]):
                    msg = (
                        f"  âš ï¸ [ğŸ’¾Redis][{name}ç»„ä»¶] "
                        f"å±æ€§ {target_column} çš„ç±»å‹ç”± {old_type} å˜æ›´ä¸º {new_type}ï¼Œ"
                        f"æ— æ³•è‡ªåŠ¨è½¬æ¢ç±»å‹ï¼Œéœ€è¦æ‰‹åŠ¨è¿ç§»ï¼Œå¼ºåˆ¶æ‰§è¡Œå°†æˆªæ–­/ä¸¢å¼ƒè¯¥å±æ€§æ•°æ®ã€‚"
                    )
                    logger.warning(msg)
                    unsafe_convert_columns.append(target_column)

    # æ£€æŸ¥æ–°å¢çš„å±æ€§æ˜¯å¦æœ‰é»˜è®¤å€¼
    target_props = dict(TARGET_COMPONENT_MODEL.properties_)
    for target_column in target_columns:
        if target_column not in down_columns:
            add_columns.append(target_column)
            logger.warning(
                f"  âš ï¸ [ğŸ’¾Redis][{name}ç»„ä»¶] "
                f"æ–°çš„ä»£ç å®šä¹‰ä¸­å¤šå‡ºå±æ€§ {target_column}ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼å¡«å……ã€‚"
            )
            default = target_props[target_column].default
            if default is None:
                msg = (
                    f"  âš ï¸ [ğŸ’¾Redis][{name}ç»„ä»¶] "
                    f"è¿ç§»æ—¶å°è¯•æ–°å¢ {target_column} å±æ€§å¤±è´¥ï¼Œè¯¥å±æ€§æ²¡æœ‰é»˜è®¤å€¼ï¼Œæ— æ³•æ–°å¢ã€‚"
                )
                logger.error(msg)
                raise ValueError(msg)

    if remove_columns or unsafe_convert_columns:
        return "unsafe"

    return "ok"


def upgrade(
    row_ids: list[int],
    down_tables: dict[str, TableReference],
    target_table: TableReference,
    client: TableMaintenance,  # è´Ÿè´£ç›´æ¥å†™å…¥æ•°æ®çš„ï¼Œä¸“ä¾›è¿ç§»ä½¿ç”¨çš„å®¢æˆ·ç«¯
) -> None:
    """å®é™…æ‰§è¡Œå‡çº§è¿ç§»çš„æ“ä½œï¼Œæœ¬æ“ä½œä¸å¯å¤±è´¥ã€‚"""
    # ä¸€äº›å±æ€§ä¿¡æ¯
    assert (
        DOWN_COMPONENT_MODEL.component_name_ == TARGET_COMPONENT_MODEL.component_name_
    )
    table_name = DOWN_COMPONENT_MODEL.component_name_
    target_columns = dict(TARGET_COMPONENT_MODEL.properties_)
    down_columns = dict(DOWN_COMPONENT_MODEL.properties_)
    down_table = down_tables[table_name]

    # ä¿®æ”¹è€çš„tableå, è€çš„è¡¨è¯»å®Œåå°±åˆ é™¤
    renamed_down_component = DOWN_COMPONENT_MODEL.duplicate(
        DOWN_COMPONENT_MODEL.namespace_, "__temp__"
    )
    renamed_down_tbl = TableReference(
        renamed_down_component, down_table.instance_name, down_table.cluster_id
    )
    client.do_rename_table_(down_table, renamed_down_tbl)
    # åˆ›å»ºè¡¨ï¼Œå¼€å§‹schemaè¿ç§»
    client.do_create_table_(target_table)

    for row_id in row_ids:
        down_row = client.get(renamed_down_tbl, row_id)
        assert down_row

        up_row = TARGET_COMPONENT_MODEL.empty_row_()

        # å¤åˆ¶å…±æœ‰åˆ—
        for col in target_columns:
            if col in down_columns:
                up_row[col] = down_row[col]

        # å¦‚æœæœ‰æ–°å¢åˆ—ï¼Œä¸ç”¨ç®¡ï¼Œempty_row_å·²ç»è‡ªåŠ¨å¡«å……äº†é»˜è®¤å€¼
        # å¦‚æœæœ‰åˆ é™¤åˆ—ï¼Œä¸ç”¨ç®¡ï¼Œup_rowå·²ç»ä¸åŒ…å«äº†
        # å¦‚æœæœ‰ç±»å‹å˜æ›´ï¼Œä¹Ÿä¸ç”¨ç®¡ï¼Œå‰é¢åœ¨å¤åˆ¶å…±æœ‰åˆ—æ—¶è‡ªåŠ¨å®Œæˆäº†

        client.upsert_row(target_table, up_row)

    # åˆ é™¤è€çš„è¡¨
    client.do_drop_table_(renamed_down_tbl)
