"""
@author: Heerozh (Zhang Jianhao)
@copyright: Copyright 2024, Heerozh. All rights reserved.
@license: Apache2.0 å¯ç”¨ä½œå•†ä¸šé¡¹ç›®ï¼Œå†éšä¾¿æ‰¾ä¸ªè§’è½æåŠç”¨åˆ°äº†æ­¤é¡¹ç›® :D
@email: heeroz@gmail.com
"""

import logging
import time
from dataclasses import dataclass
from typing import Any, override

import compression.zstd as zstd  # ä»…åœ¨ Python 3.14+ å¯ç”¨
import numpy as np

from .pipeline import JSONType, MessageProcessLayer

logger = logging.getLogger("HeTu.root")
replay = logging.getLogger("HeTu.replay")


class ZstdLayer(MessageProcessLayer):
    """
    ä½¿ç”¨python 3.14å†…ç½®çš„ compression/zstd æ¨¡å—è¿›è¡Œæ¶ˆæ¯çš„å‹ç¼©å’Œè§£å‹ç¼©ã€‚
    """

    @dataclass
    class ZstdContext:
        compressor: zstd.ZstdCompressor
        decompressor: zstd.ZstdDecompressor

    def __init__(self, level: int = 3, dict_size: int = 1024):
        """

        Parameters
        ----------
        level
            Zstdå‹ç¼©çº§åˆ«ï¼ŒèŒƒå›´ä»1ï¼ˆæœ€å¿«ï¼Œå‹ç¼©ç‡æœ€ä½ï¼‰åˆ°22ï¼ˆæœ€æ…¢ï¼Œå‹ç¼©ç‡æœ€é«˜ï¼‰ã€‚
            ä¸€èˆ¬æ¨èä½¿ç”¨3ï¼Œä¹‹åçš„é€Ÿåº¦ä¼šéå¸¸æ…¢ï¼Œä½†å‹ç¼©ç‡æå‡æœ‰é™ã€‚
        dict_size
            Zstdå­—å…¸çš„å¤§å°ï¼Œå•ä½ä¸ºå­—èŠ‚ã€‚å­—å…¸ä¿å­˜å¸¸ç”¨å­—ç¬¦ä¸²ï¼Œæ¯”å¦‚Componentçš„å±æ€§åï¼Œæå¤§å¢åŠ å‹ç¼©ç‡ã€‚
            è¾ƒå¤§çš„å­—å…¸ä¼šå¢åŠ è¿æ¥æ—¶çš„ç½‘ç»œå¼€é”€ï¼Œä¸€èˆ¬æ¨èä½¿ç”¨1024å­—èŠ‚ï¼ˆ1KBï¼‰ã€‚
        """
        super().__init__()
        self.level = level
        self.dict_size = dict_size
        self.samples: list[Any] = []
        self.zstd_dict: zstd.ZstdDict | None = None
        self.dict_message: bytes = b""
        self.last_trained_at: float = 0.0
        self.encode_count = 0
        self.encode_ratio = 0.0

    def initial_samples(self) -> list[bytes]:
        """
        è¿”å›ç”¨äºè®­ç»ƒZstdå­—å…¸çš„éšæœºç”Ÿæˆçš„æ ·æœ¬æ•°æ®ã€‚åœ¨æ²¡æœ‰çœŸå®æ•°æ®çš„æƒ…å†µä¸‹ä½¿ç”¨è¿™ä¸ªã€‚
        """
        from ...common import Permission
        from ...data import BaseComponent
        from ...data.backend import TableReference
        from ...data.sub import Subscriptions
        from ...system import SystemClusters

        rng = np.random.default_rng()

        def make_rand_sub_message(_comp: type[BaseComponent]):
            """ç”Ÿæˆä¸€ä¸ªéšæœºçš„è®¢é˜…æ›´æ–°æ¶ˆæ¯ç”¨äºæ ·æœ¬æ•°æ®"""
            default_row: np.record = _comp.new_row(id_=0)

            # å¯¹éšæœºå±æ€§è¿›è¡Œéšæœºå¡«å……ï¼Œè¿™æ˜¯ä¸ºäº†åªä¿ç•™keyç‰¹å¾ã€‚æˆ‘ä»¬è¿™é‡Œæ”¾å¼ƒå€¼é‡å¤ç‰¹å¾ã€‚
            dt = default_row.dtype
            raw = bytearray(default_row.tobytes())  # æ‹·è´ä¸ºå¯å˜ bytes
            raw[:] = rng.integers(0, 256, size=len(raw), dtype=np.uint8).tobytes()
            default_row = np.frombuffer(raw, dtype=dt, count=1)[0]  # ç»“æ„åŒ–æ ‡é‡
            row_dict = _comp.struct_to_dict(default_row)
            del row_dict["_version"]  # åˆ é™¤ç‰ˆæœ¬å­—æ®µ

            # å¯¹è®¢é˜…idéšæœºå¡«å……ï¼Œè¿™æ˜¯ä¸ºäº†åªä¿ç•™keyç‰¹å¾ã€‚æˆ‘ä»¬è¿™é‡Œæ”¾å¼ƒå€¼é‡å¤ç‰¹å¾ã€‚
            ref = TableReference(_comp, "", 0)
            sub_id = Subscriptions.make_query_id_(
                ref,
                rng.choice(["id"] + list(row_dict.keys())),
                rng.integers(0, np.iinfo(np.int64).max),
                rng.integers(0, np.iinfo(np.int64).max),
                rng.integers(1, 100),
                rng.choice([True, False]),
            )

            return ["updt", sub_id, row_dict]

        samples = []
        # cherry pickæ ·æœ¬
        for comp, _ in SystemClusters().get_components().items():
            if comp.permission_ == Permission.ADMIN:
                continue

            # zstdç®—æ³•(COVER)éœ€è¦ç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œéœ€è¦è¯†åˆ«é‡å¤æ¨¡å¼è€Œéè®°ä½å®Œæ•´å†…å®¹
            for _ in range(200):
                sub_message = make_rand_sub_message(comp)
                # æŠŠè®¢é˜…æ›´æ–°æ¶ˆæ¯ç¼–ç åˆ°å‹ç¼©å‰
                if self._parent:
                    encoded_message = self._parent.encode(
                        [None] * (self._layer_idx + 1), sub_message, self._layer_idx
                    )
                else:
                    encoded_message = str(sub_message).encode("utf-8")
                samples.append(encoded_message)

        if len(samples) == 0:
            # å…œåº•ï¼Œé˜²æ­¢æ²¡æœ‰æ ·æœ¬
            for _ in range(1000):
                samples.append(b"updt FutureCall id")

        return samples

    def train_dict(self) -> zstd.ZstdDict:
        """
        è®­ç»ƒZstdå­—å…¸ä»¥æé«˜å‹ç¼©æ•ˆç‡ã€‚
        ä½¿ç”¨æ‰€æœ‰éAdminçš„ç»„ä»¶ï¼Œåˆ›å»ºä¸€è¡Œé»˜è®¤å€¼æ•°æ®ï¼Œç„¶åç”¨pipelineåœ¨æœ¬å±‚ä¹‹å‰è¿›è¡Œé¢„å¤„ç†ï¼Œ
        ç„¶åç”¨å®ƒä»¬ä½œä¸ºæ ·æœ¬ã€‚
        """
        # å¦‚æœæœ‰è¿è¡ŒæœŸé—´æ”¶é›†çš„æ•°æ®ï¼Œç”¨å®ƒä»¬è®­ç»ƒ
        if len(self.samples) > 1000:
            samples = self.samples
        else:
            # å¦åˆ™ä½¿ç”¨åˆå§‹æ ·æœ¬
            samples = self.initial_samples()
        # è®­ç»ƒZstdå­—å…¸
        return zstd.train_dict(samples, self.dict_size)

    @override
    def handshake(self, message: bytes) -> tuple[Any, bytes]:
        """
        è¿æ¥å‰æ¡æ‰‹å·¥ä½œï¼Œä¾‹å¦‚åå•†å‚æ•°ç­‰ã€‚
        è¿”å›çš„ç¬¬ä¸€ä¸ªå€¼ä¼šä¿å­˜åœ¨è¿æ¥ä¸­ï¼Œè´¯ç©¿ä¹‹åçš„encode/decodeè°ƒç”¨ã€‚
        è¿”å›çš„ç¬¬äºŒä¸ªå€¼ä¼šå‘é€ç»™å¯¹ç«¯ã€‚
        """
        if len(message) == 0:
            # å¦‚æœæ²¡æœ‰è®­ç»ƒè¿‡å­—å…¸ï¼Œç”¨åˆå§‹æ ·æœ¬è®­ç»ƒ
            if self.zstd_dict is None:
                self.zstd_dict = self.train_dict()
                self.last_trained_at = time.time()
                self.dict_message = self.zstd_dict.dict_content
            else:
                # åä¹‹å®šæœŸçš„æ›´æ–°å­—å…¸
                # todo å¦‚æœä¸Šæ¬¡è®­ç»ƒæ—¶é—´è¶…è¿‡24å°æ—¶ï¼Œé‡æ–°è®­ç»ƒå­—å…¸
                pass
        else:
            # å¦‚æœå¯¹ç«¯å‘é€äº†å­—å…¸æ•°æ®ï¼Œä½¿ç”¨å¯¹ç«¯çš„å­—å…¸
            self.zstd_dict = zstd.ZstdDict(message)
            self.dict_message = self.zstd_dict.dict_content

        assert self.dict_message

        ctx = self.ZstdContext(
            compressor=zstd.ZstdCompressor(
                level=self.level,
                # as_digested_dictä¼šåœ¨self.zstd_dictå†…éƒ¨å»ºç«‹å·²æ¶ˆåŒ–å­—å…¸çš„cacheï¼Œè®©ä¸‹æ¬¡åŠ è½½æ›´å¿«
                # ä½†æ˜¯éƒ¨åˆ†å‹ç¼©å‚æ•°ä¼šæœ‰è¢«å­—å…¸çš„å‚æ•°è¦†ç›–ï¼Œè¿™é‡Œæ²¡ç”¨åˆ°é‚£äº›å‚æ•°æ‰€ä»¥æ— å¦¨
                zstd_dict=self.zstd_dict.as_digested_dict,
            ),
            decompressor=zstd.ZstdDecompressor(zstd_dict=self.zstd_dict),
        )
        return ctx, self.dict_message

    @override
    def encode(self, layer_ctx: Any, message: JSONType | bytes) -> JSONType | bytes:
        """
        å¯¹æ¶ˆæ¯è¿›è¡Œæ­£å‘å¤„ç†ï¼ˆæµå¼å‹ç¼©ï¼‰
        """
        # å¦‚æœæ²¡æœ‰ ctx (æ¡æ‰‹æœªå®Œæˆ/æœªåå•†å­—å…¸)ï¼Œç›´æ¥è¿”å›åŸå§‹æ¶ˆæ¯
        if not layer_ctx:
            return message

        assert type(message) is bytes, "ZstdCompressoråªèƒ½å‹ç¼©bytesç±»å‹çš„æ¶ˆæ¯"

        # todo å¦‚æœself.samplesé•¿åº¦ä¸è¶³ï¼Œè¯´æ˜è¢«æ¸…ç©ºäº†ï¼Œæ”¶é›†æ ·æœ¬æ•°æ®ä»¥ä¾¿åç»­è®­ç»ƒå­—å…¸
        # todoï¼Œ è®°å½•å®é™…å‹ç¼©æ¯”ç‡ï¼Œå’Œå‹ç¼©è€—æ—¶ï¼Œå¯¹åº”levelå’Œdict_sizeå‚æ•°ï¼Œä»¥ä¾¿åç»­è°ƒä¼˜

        # ä½¿ç”¨é¢„è®­ç»ƒçš„å­—å…¸è¿›è¡Œå‹ç¼©
        # 1. å†™å…¥æ•°æ®åˆ°æµ
        # 2. FLUSH_BLOCK:
        #    è¿™ä¼šå¼ºåˆ¶è¾“å‡ºå½“å‰å—çš„æ•°æ®ï¼Œç¡®ä¿æ¥æ”¶ç«¯èƒ½ç«‹å³æ”¶åˆ°å¹¶è§£å‹ã€‚
        #    åŒæ—¶ä¸ä¼šç»“æŸå½“å‰å¸§ (Frame)ï¼Œä¿ç•™äº†å†å²å‚è€ƒä¿¡æ¯ï¼ˆæµå¼å‹ç¼©çš„æ ¸å¿ƒä¼˜åŠ¿ï¼‰ã€‚
        chunk = layer_ctx.compressor.compress(
            message, mode=zstd.ZstdCompressor.FLUSH_BLOCK
        )
        ratio = len(chunk) / len(message)
        self.encode_count += 1
        self.encode_ratio += (ratio - self.encode_ratio) / self.encode_count
        return chunk

    @override
    def decode(self, layer_ctx: Any, message: JSONType | bytes) -> JSONType | bytes:
        """
        å¯¹æ¶ˆæ¯è¿›è¡Œé€†å‘å¤„ç†ï¼ˆæµå¼è§£å‹ï¼‰
        """
        # å¦‚æœæ²¡æœ‰ ctxï¼Œå‡è®¾æ¶ˆæ¯æ˜¯æœªå‹ç¼©çš„åŸå§‹æ ¼å¼
        if not layer_ctx:
            return message

        assert type(message) is bytes, "ZstdDecompressoråªèƒ½è§£å‹bytesç±»å‹çš„æ¶ˆæ¯"

        # åä¹‹ï¼Œä½¿ç”¨å­—å…¸æµå¼è§£å‹
        # zstd æ¨¡å—ä¼šè‡ªåŠ¨å¤„ç†è·¨åŒ…çš„æ•°æ®ç¼“å†²
        try:
            return layer_ctx.decompressor.decompress(message)
        except Exception as e:
            # è§£å‹å¤±è´¥å¤„ç†
            logger.exception(
                f"âŒ [ğŸ“¡Pipeline] [Zstdå±‚] è§£å‹å¤±è´¥ï¼Œå¼‚å¸¸ï¼š{type(e).__name__}:{e}"
            )
            raise
